{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codecs import open\n",
    "from __future__ import division\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_documents(doc_file):\n",
    "    docs = []\n",
    "    labels = []\n",
    "    with open(doc_file, encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            words = line.strip().split()\n",
    "            docs.append(words[3:])\n",
    "            labels.append(words[1])\n",
    "        #print(docs[0],labels[0])\n",
    "    return docs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_docs, all_labels = read_documents('all_sentiment_shuffled.txt')\n",
    "all_docs, all_labels = read_documents('trunc_sentiment_shuffled.txt')\n",
    "\n",
    "split_point = int(0.80*len(all_docs))\n",
    "train_docs = all_docs[:split_point]\n",
    "train_labels = all_labels[:split_point]  \n",
    "val_docs = all_docs[split_point:]\n",
    "val_labels = all_labels[split_point:]\n",
    "#print(val_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nb(documents, labels):\n",
    "    \n",
    "    freqs_pos = Counter()\n",
    "    freqs_neg = Counter()\n",
    "    \n",
    "    for i in range(len(documents)):\n",
    "        lines=documents[i]\n",
    "        for word in lines:\n",
    "            #print(\"word-\",word)\n",
    "            #print(\"train_labels[i]-\",train_labels[i])\n",
    "            if labels[i] == 'pos':\n",
    "                freqs_pos[word] += 1\n",
    "            else:\n",
    "                freqs_neg[word] += 1\n",
    "   \n",
    "    print(\"Words with pos and neg label-\",freqs_pos, freqs_neg)\n",
    "       \n",
    "    total_pos_words = sum(freqs_pos.values())\n",
    "    total_neg_words = sum(freqs_neg.values())\n",
    "    print(\"Total pos & neg values\", total_pos_words,total_neg_words )\n",
    "    \n",
    "    #find probability of each word appearing with pos and neg labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words with pos label- Counter({'the': 4, '.': 4, 'to': 4, 'is': 2, 'these': 2, 'are': 2, 'great': 2, 'and': 2, 'i': 2, 'a': 2, 'they': 2, 'anything': 1, 'you': 1, 'purchase': 1, 'in': 1, 'left': 1, 'behind': 1, 'series': 1, 'an': 1, 'excellent': 1, 'read': 1, 'books': 1, 'very': 1, 'close': 1, 'bible': 1, 'have': 1, 'entire': 1, 'set': 1, 'amazon': 1, 'shopping': 1, 'site': 1, 'ship': 1, 'fast': 1, 'would': 1, 'recommend': 1, 'any': 1, 'christian': 1, 'wanting': 1, 'know': 1, 'about': 1, 'what': 1, 'expect': 1, 'during': 1, 'return': 1, 'of': 1, 'christ': 1, '!': 1, 'fiction': 1, 'but': 1, 'still': 1, 'makes': 1, 'good': 1, 'point': 1})\n",
      "Words with neg label- Counter({'the': 14, '.': 12, 'and': 11, 'i': 9, 'of': 8, 'this': 7, ',': 7, 'to': 7, 'it': 6, 'is': 6, \"'s\": 5, 'a': 4, 'song': 3, 'are': 3, 'in': 3, 'music': 3, 'out': 3, 'my': 3, 'was': 3, 'her': 3, 'album': 2, 'can': 2, 'rest': 2, 'be': 2, 'for': 2, 'as': 2, 'he': 2, 'keep': 2, 'buying': 2, 'garbage': 2, 'get': 2, 'country': 2, 'really': 2, 'what': 2, 'one': 2, 'bought': 1, 'because': 1, 'loved': 1, 'title': 1, 'such': 1, 'great': 1, 'how': 1, 'bad': 1, 'right': 1, '?': 1, 'well': 1, 'songs': 1, 'just': 1, 'filler': 1, \"n't\": 1, 'worth': 1, 'money': 1, 'paid': 1, 'either': 1, 'shameless': 1, 'bubblegum': 1, 'or': 1, 'oversentimentalized': 1, 'depressing': 1, 'tripe': 1, 'kenny': 1, 'chesney': 1, 'popular': 1, 'artist': 1, 'result': 1, 'cookie': 1, 'cutter': 1, 'category': 1, 'nashville': 1, 'scene': 1, 'gotta': 1, 'pump': 1, 'albums': 1, 'so': 1, 'record': 1, 'company': 1, 'lining': 1, 'their': 1, 'pockets': 1, 'while': 1, 'suckers': 1, 'there': 1, 'perpetuate': 1, 'more': 1, 'coming': 1, 'that': 1, 'town': 1, \"'ll\": 1, 'down': 1, 'off': 1, 'soapbox': 1, 'now': 1, 'but': 1, 'needs': 1, 'back': 1, 'roots': 1, 'stop': 1, 'pop': 1, 'nonsense': 1, 'considered': 1, 'by': 1, 'mainstream': 1, 'two': 1, 'different': 1, 'things': 1, 'misled': 1, 'thought': 1, 'entire': 1, 'cd': 1, 'contains': 1, 'have': 1, 'introduced': 1, 'many': 1, 'ell': 1, 'high': 1, 'school': 1, 'students': 1, 'lois': 1, 'lowery': 1, 'depth': 1, 'characters': 1, 'she': 1, 'brilliant': 1, 'writer': 1, 'capable': 1, 'inspiring': 1, 'fierce': 1, 'passion': 1, 'readers': 1, 'they': 1, 'encounter': 1, 'shocking': 1, 'details': 1, 'utopian': 1, 'worlds': 1, 'anxious': 1, 'read': 1, 'companion': 1, 'novel': 1, 'had': 1, 'planned': 1, 'share': 1, 'with': 1, 'class': 1, 'january': 1, 'although': 1, 'series': 1, 'written': 1, '6th': 1, 'graders': 1, 'older': 1, 'book': 1, 'simplicity': 1, 'its': 1, 'message': 1, 'language': 1, 'writing': 1, 'style': 1, 'will': 1, 'inspire': 1, 'no': 1, 'am': 1, 'sadly': 1, 'disappointed': 1})\n",
      "Total pos & neg values 70 279\n"
     ]
    }
   ],
   "source": [
    "train_nb(train_docs, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "word- i\n",
      "word- bought\n",
      "word- this\n",
      "word- album\n",
      "word- because\n",
      "word- i\n",
      "word- loved\n",
      "word- the\n",
      "word- title\n",
      "word- song\n",
      "word- .\n",
      "word- it\n",
      "word- 's\n",
      "word- such\n",
      "word- a\n",
      "word- great\n",
      "word- song\n",
      "word- ,\n",
      "word- how\n",
      "word- bad\n",
      "word- can\n",
      "word- the\n",
      "word- rest\n",
      "word- of\n",
      "word- the\n",
      "word- album\n",
      "word- be\n",
      "word- ,\n",
      "word- right\n",
      "word- ?\n",
      "word- well\n",
      "word- ,\n",
      "word- the\n",
      "word- rest\n",
      "word- of\n",
      "word- the\n",
      "word- songs\n",
      "word- are\n",
      "word- just\n",
      "word- filler\n",
      "word- and\n",
      "word- are\n",
      "word- n't\n",
      "word- worth\n",
      "word- the\n",
      "word- money\n",
      "word- i\n",
      "word- paid\n",
      "word- for\n",
      "word- this\n",
      "word- .\n",
      "word- it\n",
      "word- 's\n",
      "word- either\n",
      "word- shameless\n",
      "word- bubblegum\n",
      "word- or\n",
      "word- oversentimentalized\n",
      "word- depressing\n",
      "word- tripe\n",
      "word- .\n",
      "word- kenny\n",
      "word- chesney\n",
      "word- is\n",
      "word- a\n",
      "word- popular\n",
      "word- artist\n",
      "word- and\n",
      "word- as\n",
      "word- a\n",
      "word- result\n",
      "word- he\n",
      "word- is\n",
      "word- in\n",
      "word- the\n",
      "word- cookie\n",
      "word- cutter\n",
      "word- category\n",
      "word- of\n",
      "word- the\n",
      "word- nashville\n",
      "word- music\n",
      "word- scene\n",
      "word- .\n",
      "word- he\n",
      "word- 's\n",
      "word- gotta\n",
      "word- pump\n",
      "word- out\n",
      "word- the\n",
      "word- albums\n",
      "word- so\n",
      "word- the\n",
      "word- record\n",
      "word- company\n",
      "word- can\n",
      "word- keep\n",
      "word- lining\n",
      "word- their\n",
      "word- pockets\n",
      "word- while\n",
      "word- the\n",
      "word- suckers\n",
      "word- out\n",
      "word- there\n",
      "word- keep\n",
      "word- buying\n",
      "word- this\n",
      "word- garbage\n",
      "word- to\n",
      "word- perpetuate\n",
      "word- more\n",
      "word- garbage\n",
      "word- coming\n",
      "word- out\n",
      "word- of\n",
      "word- that\n",
      "word- town\n",
      "word- .\n",
      "word- i\n",
      "word- 'll\n",
      "word- get\n",
      "word- down\n",
      "word- off\n",
      "word- my\n",
      "word- soapbox\n",
      "word- now\n",
      "word- .\n",
      "word- but\n",
      "word- country\n",
      "word- music\n",
      "word- really\n",
      "word- needs\n",
      "word- to\n",
      "word- get\n",
      "word- back\n",
      "word- to\n",
      "word- it\n",
      "word- 's\n",
      "word- roots\n",
      "word- and\n",
      "word- stop\n",
      "word- this\n",
      "word- pop\n",
      "word- nonsense\n",
      "word- .\n",
      "word- what\n",
      "word- country\n",
      "word- music\n",
      "word- really\n",
      "word- is\n",
      "word- and\n",
      "word- what\n",
      "word- it\n",
      "word- is\n",
      "word- considered\n",
      "word- to\n",
      "word- be\n",
      "word- by\n",
      "word- mainstream\n",
      "word- are\n",
      "word- two\n",
      "word- different\n",
      "word- things\n",
      "word- .\n",
      "word- i\n",
      "word- was\n",
      "word- misled\n",
      "word- and\n",
      "word- thought\n",
      "word- i\n",
      "word- was\n",
      "word- buying\n",
      "word- the\n",
      "word- entire\n",
      "word- cd\n",
      "word- and\n",
      "word- it\n",
      "word- contains\n",
      "word- one\n",
      "word- song\n",
      "word- i\n",
      "word- have\n",
      "word- introduced\n",
      "word- many\n",
      "word- of\n",
      "word- my\n",
      "word- ell\n",
      "word- ,\n",
      "word- high\n",
      "word- school\n",
      "word- students\n",
      "word- to\n",
      "word- lois\n",
      "word- lowery\n",
      "word- and\n",
      "word- the\n",
      "word- depth\n",
      "word- of\n",
      "word- her\n",
      "word- characters\n",
      "word- .\n",
      "word- she\n",
      "word- is\n",
      "word- a\n",
      "word- brilliant\n",
      "word- writer\n",
      "word- and\n",
      "word- capable\n",
      "word- of\n",
      "word- inspiring\n",
      "word- fierce\n",
      "word- passion\n",
      "word- in\n",
      "word- her\n",
      "word- readers\n",
      "word- as\n",
      "word- they\n",
      "word- encounter\n",
      "word- shocking\n",
      "word- details\n",
      "word- of\n",
      "word- her\n",
      "word- utopian\n",
      "word- worlds\n",
      "word- .\n",
      "word- i\n",
      "word- was\n",
      "word- anxious\n",
      "word- to\n",
      "word- read\n",
      "word- this\n",
      "word- companion\n",
      "word- novel\n",
      "word- and\n",
      "word- had\n",
      "word- planned\n",
      "word- to\n",
      "word- share\n",
      "word- it\n",
      "word- with\n",
      "word- my\n",
      "word- class\n",
      "word- this\n",
      "word- january\n",
      "word- .\n",
      "word- although\n",
      "word- the\n",
      "word- series\n",
      "word- is\n",
      "word- written\n",
      "word- for\n",
      "word- 6th\n",
      "word- graders\n",
      "word- and\n",
      "word- older\n",
      "word- ,\n",
      "word- this\n",
      "word- book\n",
      "word- 's\n",
      "word- simplicity\n",
      "word- ,\n",
      "word- in\n",
      "word- its\n",
      "word- message\n",
      "word- ,\n",
      "word- language\n",
      "word- and\n",
      "word- writing\n",
      "word- style\n",
      "word- will\n",
      "word- inspire\n",
      "word- no\n",
      "word- one\n",
      "word- .\n",
      "word- i\n",
      "word- am\n",
      "word- sadly\n",
      "word- disappointed\n",
      "word- anything\n",
      "word- you\n",
      "word- purchase\n",
      "word- in\n",
      "word- the\n",
      "word- left\n",
      "word- behind\n",
      "word- series\n",
      "word- is\n",
      "word- an\n",
      "word- excellent\n",
      "word- read\n",
      "word- .\n",
      "word- these\n",
      "word- books\n",
      "word- are\n",
      "word- great\n",
      "word- and\n",
      "word- very\n",
      "word- close\n",
      "word- to\n",
      "word- the\n",
      "word- bible\n",
      "word- .\n",
      "word- i\n",
      "word- have\n",
      "word- the\n",
      "word- entire\n",
      "word- set\n",
      "word- .\n",
      "word- amazon\n",
      "word- is\n",
      "word- a\n",
      "word- great\n",
      "word- shopping\n",
      "word- site\n",
      "word- and\n",
      "word- they\n",
      "word- ship\n",
      "word- fast\n",
      "word- .\n",
      "word- i\n",
      "word- would\n",
      "word- recommend\n",
      "word- these\n",
      "word- to\n",
      "word- any\n",
      "word- christian\n",
      "word- wanting\n",
      "word- to\n",
      "word- know\n",
      "word- about\n",
      "word- what\n",
      "word- to\n",
      "word- expect\n",
      "word- during\n",
      "word- the\n",
      "word- return\n",
      "word- of\n",
      "word- christ\n",
      "word- !\n",
      "word- they\n",
      "word- are\n",
      "word- fiction\n",
      "word- but\n",
      "word- still\n",
      "word- makes\n",
      "word- a\n",
      "word- good\n",
      "word- point\n",
      "words with pos label- Counter({'the': 4, '.': 4, 'to': 4, 'is': 2, 'these': 2, 'are': 2, 'great': 2, 'and': 2, 'i': 2, 'a': 2, 'they': 2, 'anything': 1, 'you': 1, 'purchase': 1, 'in': 1, 'left': 1, 'behind': 1, 'series': 1, 'an': 1, 'excellent': 1, 'read': 1, 'books': 1, 'very': 1, 'close': 1, 'bible': 1, 'have': 1, 'entire': 1, 'set': 1, 'amazon': 1, 'shopping': 1, 'site': 1, 'ship': 1, 'fast': 1, 'would': 1, 'recommend': 1, 'any': 1, 'christian': 1, 'wanting': 1, 'know': 1, 'about': 1, 'what': 1, 'expect': 1, 'during': 1, 'return': 1, 'of': 1, 'christ': 1, '!': 1, 'fiction': 1, 'but': 1, 'still': 1, 'makes': 1, 'good': 1, 'point': 1})\n",
      "words with neg label- Counter({'the': 14, '.': 12, 'and': 11, 'i': 9, 'of': 8, 'this': 7, ',': 7, 'to': 7, 'it': 6, 'is': 6, \"'s\": 5, 'a': 4, 'song': 3, 'are': 3, 'in': 3, 'music': 3, 'out': 3, 'my': 3, 'was': 3, 'her': 3, 'album': 2, 'can': 2, 'rest': 2, 'be': 2, 'for': 2, 'as': 2, 'he': 2, 'keep': 2, 'buying': 2, 'garbage': 2, 'get': 2, 'country': 2, 'really': 2, 'what': 2, 'one': 2, 'bought': 1, 'because': 1, 'loved': 1, 'title': 1, 'such': 1, 'great': 1, 'how': 1, 'bad': 1, 'right': 1, '?': 1, 'well': 1, 'songs': 1, 'just': 1, 'filler': 1, \"n't\": 1, 'worth': 1, 'money': 1, 'paid': 1, 'either': 1, 'shameless': 1, 'bubblegum': 1, 'or': 1, 'oversentimentalized': 1, 'depressing': 1, 'tripe': 1, 'kenny': 1, 'chesney': 1, 'popular': 1, 'artist': 1, 'result': 1, 'cookie': 1, 'cutter': 1, 'category': 1, 'nashville': 1, 'scene': 1, 'gotta': 1, 'pump': 1, 'albums': 1, 'so': 1, 'record': 1, 'company': 1, 'lining': 1, 'their': 1, 'pockets': 1, 'while': 1, 'suckers': 1, 'there': 1, 'perpetuate': 1, 'more': 1, 'coming': 1, 'that': 1, 'town': 1, \"'ll\": 1, 'down': 1, 'off': 1, 'soapbox': 1, 'now': 1, 'but': 1, 'needs': 1, 'back': 1, 'roots': 1, 'stop': 1, 'pop': 1, 'nonsense': 1, 'considered': 1, 'by': 1, 'mainstream': 1, 'two': 1, 'different': 1, 'things': 1, 'misled': 1, 'thought': 1, 'entire': 1, 'cd': 1, 'contains': 1, 'have': 1, 'introduced': 1, 'many': 1, 'ell': 1, 'high': 1, 'school': 1, 'students': 1, 'lois': 1, 'lowery': 1, 'depth': 1, 'characters': 1, 'she': 1, 'brilliant': 1, 'writer': 1, 'capable': 1, 'inspiring': 1, 'fierce': 1, 'passion': 1, 'readers': 1, 'they': 1, 'encounter': 1, 'shocking': 1, 'details': 1, 'utopian': 1, 'worlds': 1, 'anxious': 1, 'read': 1, 'companion': 1, 'novel': 1, 'had': 1, 'planned': 1, 'share': 1, 'with': 1, 'class': 1, 'january': 1, 'although': 1, 'series': 1, 'written': 1, '6th': 1, 'graders': 1, 'older': 1, 'book': 1, 'simplicity': 1, 'its': 1, 'message': 1, 'language': 1, 'writing': 1, 'style': 1, 'will': 1, 'inspire': 1, 'no': 1, 'am': 1, 'sadly': 1, 'disappointed': 1})\n"
     ]
    }
   ],
   "source": [
    "example_documents = ['the first document'.split(), 'the second document'.split()]\n",
    "#example_documents = [\" \".join(train_docs[0]).split(), \" \".join(train_docs[1]).split()]\n",
    "\n",
    "freqs1 = Counter()\n",
    "\n",
    "for doc in example_documents:\n",
    "    for w in doc:\n",
    "        freqs1[w] += 1\n",
    "\n",
    "freqs2 = Counter()\n",
    "for doc in example_documents:\n",
    "    freqs2.update(doc)\n",
    "\n",
    "freqs3 = Counter(w for doc in example_documents for w in doc)\n",
    "\n",
    "\n",
    "print(freqs1)\n",
    "print(freqs1['the'])\n",
    "print(freqs1['neverseen'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
